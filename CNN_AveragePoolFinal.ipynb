{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-19/INT2_Open_Assessment/blob/main/CNN_AveragePoolFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ffbf9ecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffbf9ecd",
        "outputId": "665df829-00df-4659-d65a-1096dc310592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:16<00:00, 21512163.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 635347.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 10737561.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 10.3742, Train Acc: 2.06%\n",
            "Epoch [2/10], Train Loss: 5.1189, Train Acc: 1.18%\n",
            "Epoch [3/10], Train Loss: 4.4792, Train Acc: 4.71%\n",
            "Epoch [4/10], Train Loss: 4.3521, Train Acc: 3.82%\n",
            "Epoch [5/10], Train Loss: 4.2218, Train Acc: 7.16%\n",
            "Epoch [6/10], Train Loss: 4.0803, Train Acc: 8.53%\n",
            "Epoch [7/10], Train Loss: 3.9901, Train Acc: 8.14%\n",
            "Epoch [8/10], Train Loss: 3.8712, Train Acc: 11.27%\n",
            "Epoch [9/10], Train Loss: 3.7964, Train Acc: 14.12%\n",
            "Epoch [10/10], Train Loss: 3.7426, Train Acc: 13.14%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 10            # Maximum Number of epochs to train the network\n",
        "batch_size = 64             \n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define transforms with data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomVerticalFlip(p=0.05),\n",
        "    transforms.RandomHorizontalFlip(p=0.1),\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.ColorJitter(contrast=0.25, saturation=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Flower102: Unknown number and various sized color images in 102 classes, with 40 to 258 images per class\n",
        "train_dataset = torchvision.datasets.Flowers102(root='./data', split='train',\n",
        "                                                download=True, transform=train_transform)\n",
        "test_dataset = torchvision.datasets.Flowers102(root='./data', split='test',\n",
        "                                               download=True, transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# Convolutional neural network\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.avPool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(25088, 2048)\n",
        "        self.fc2 = nn.Linear(2048, num_classes)\n",
        "        self.drop = nn.Dropout(0.4)\n",
        "        # Batch normalisation and Max Pooling used on convolution layers, dropout 40% used on fully connected linear layers\n",
        "        # All layers have Relu Applied\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.pool(out)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.pool(out)\n",
        "        out = F.relu(self.bn3(self.conv3(out)))\n",
        "        out = self.pool(out)\n",
        "        out = F.relu(self.bn4(self.conv4(out)))\n",
        "        out = self.pool(out)\n",
        "        out = F.relu(self.bn5(self.conv5(out)))\n",
        "        out = self.avPool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = F.relu(self.drop(self.fc1(out)))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Create model and push to device\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "# Get loss and optimiser\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "Runs the current model on the training data to calculate the current loss and accuracy of the epoch.\n",
        "For the training set, label smoothness is added to introduce randomness to prevent overfitting.\n",
        "\n",
        "Args:\n",
        "  model: Current version of the training model\n",
        "  train_loader: The data loader responsible for loading the training set from the Flowers102 dataset \n",
        "  criterion: The loss function\n",
        "  optimiser: The optimising function applied to the learning model\n",
        "  device: The hardware accelerator that is being used to train the model\n",
        "  smoothing: Value applied for label smoothing\n",
        "\n",
        "Returns:\n",
        "  Two values, a float value which is the loss from the current epoch and\n",
        "  and accuracy a float value representing a percentage of the current accuracy for the training data\n",
        "'''\n",
        "def train(model, train_loader, criterion, optimiser, device, epoch, smoothing=0.1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Apply label smoothing\n",
        "        num_classes = model.fc2.out_features\n",
        "        one_hot_labels = torch.zeros(labels.size(0), num_classes).to(device)\n",
        "        one_hot_labels.scatter_(1, labels.view(-1, 1), 1)\n",
        "        one_hot_labels = one_hot_labels * (1 - smoothing) + smoothing / num_classes\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, one_hot_labels)\n",
        "\n",
        "        # Backward and optimise\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    loss = train_loss / len(train_loader)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "'''\n",
        "Runs the current model on the validation data to calculate the test the current accuracy and loss of the epoch.\n",
        "\n",
        "Args:\n",
        "  model: Current version of the training model\n",
        "  train_loader: The data loader responsible for loading the validation set from the Flowers102 dataset \n",
        "  criterion: The loss function\n",
        "  device: The hardware accelerator that is being used to train the model\n",
        "\n",
        "Returns:\n",
        "  Two values, a float value which is the loss from the current epoch and\n",
        "  and accuracy a float value representing a percentage of the current accuracy for the validation data\n",
        "'''\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    loss = test_loss / len(test_loader)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "# Training the model\n",
        "train_losses, train_accs, valid_losses, valid_accs = [], [], [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimiser, device, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # Times validation accuracy is calculated is adjusted for debugging and data analysis purposes. \n",
        "    if ((epoch + 1) % 25 == 0):\n",
        "      valid_loss, valid_acc = test(model, test_loader, criterion, device)\n",
        "      valid_losses.append(valid_loss)   \n",
        "      valid_accs.append(valid_acc)\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.2f}%')\n",
        "    else:\n",
        "      print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "\n",
        "# Save the model\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}