{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INT2-19/INT2_PyTorch-CrashCourse/blob/main/INT2_PyTorch_CrashCourse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2022 AssemblyAI Team."
      ],
      "metadata": {
        "id": "lCHxjzMCGgm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Crash Course\n",
        "\n",
        "#### Overview:\n",
        "\n",
        "1. Tensor Basics\n",
        "  - Create, Operations, NumPy, GPU Support\n",
        "2. Autograd\n",
        "  - Linear regression example\n",
        "3. Training Loop with: Model, Loss & Optimizer\n",
        "  - A typical PyTorch training pipeline\n",
        "4. Neural Network\n",
        "  - Also: GPU, Datasets, DataLoader, Transforms & Evaluation\n",
        "5. Convolutional Neural Network\n",
        "  - Also: Save/Load model"
      ],
      "metadata": {
        "id": "MAcpE-kjwVML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created by [AssemblyAI](https://www.assemblyai.com)\n",
        "\n",
        "Watch the video:\n",
        "\n",
        " [![Alt text](https://img.youtube.com/vi/OIenNRt2bjg/hqdefault.jpg)](https://youtu.be/mYUyaKmvu6Y)"
      ],
      "metadata": {
        "id": "y6ft2IN4F6sV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tensors\n",
        "\n",
        "Everything in PyTorch is based on Tensor operations. A Tensor is a multi-dimensional matrix containing elements of a single data type:\n"
      ],
      "metadata": {
        "id": "mUT_7ZCPwY9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3mWV8uTgo4Bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434bbf75-607e-4e0b-cce5-849e657b4411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "empty(1): tensor([-1.6318e-15])\n",
            "empty(3): tensor([-1.6318e-15,  4.5743e-41,  5.0343e-38])\n",
            "empty(2,3): tensor([[-1.6318e-15,  4.5743e-41,  9.3252e+02],\n",
            "        [ 0.0000e+00, -2.2413e+04,  4.5741e-41]])\n",
            "empty(2, 2, 3): tensor([[[9.3528e+02, 0.0000e+00, 5.0310e-38],\n",
            "         [0.0000e+00, 5.0320e-38, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
            "rand(5,3): tensor([[0.8245, 0.7081, 0.2508],\n",
            "        [0.1826, 0.2950, 0.9057],\n",
            "        [0.9586, 0.1267, 0.4341],\n",
            "        [0.3352, 0.6089, 0.6490],\n",
            "        [0.5805, 0.5943, 0.3265]])\n",
            "zeros(5,3): tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(\"empty(1):\", x)\n",
        "x = torch.empty(3) # vector\n",
        "print(\"empty(3):\",x)\n",
        "x = torch.empty(2, 3) # matrix\n",
        "print(\"empty(2,3):\",x)\n",
        "x = torch.empty(2, 2, 3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(\"empty(2, 2, 3):\",x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(\"rand(5,3):\", x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(\"zeros(5,3):\", x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check size\n",
        "print(\"size\", x.size())  # x.size(0)\n",
        "print(\"shape\", x.shape)  # x.shape[0]"
      ],
      "metadata": {
        "id": "Asq_Sgh7cJnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5efe9440-bcde-49c4-ef14-2b11b3cb8fdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size torch.Size([5, 3])\n",
            "shape torch.Size([5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "id": "DmDNPMrp_zLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81825af6-b4bc-4cf5-9192-083e4d5d81b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x, x.dtype)"
      ],
      "metadata": {
        "id": "sj2VAgMM_2Vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b020235b-2911-4eb4-ce3e-e1db851b03c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "uT-3O8wtcMeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007560a3-2651-4e8c-ffc0-41a041e1216a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Operations with Tensors"
      ],
      "metadata": {
        "id": "_cDRipePEhZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Operations\n",
        "x = torch.ones(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "id": "3pjK4YL6ES9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476fca73-5cc5-419d-9811-0f33e7433501"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.1132, 0.8020],\n",
            "        [0.8704, 0.2056]])\n",
            "tensor([[1.1132, 1.8020],\n",
            "        [1.8704, 1.2056]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)"
      ],
      "metadata": {
        "id": "qXEAxoExC2aq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(\"x[:, 0]\", x[:, 0]) # all rows, column 0\n",
        "print(\"x[1, :]\", x[1, :]) # row 1, all columns\n",
        "print(\"x[1, 1]\", x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(\"x[1,1].item()\", x[1,1].item())"
      ],
      "metadata": {
        "id": "KPmWwGnIClh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f5c297-d002-4907-9341-24a8fd04235a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.2585e-01, 5.0286e-01, 6.1202e-04],\n",
            "        [9.4674e-01, 2.8100e-01, 8.4475e-01],\n",
            "        [4.7182e-01, 6.5903e-01, 1.3534e-01],\n",
            "        [1.1015e-01, 8.8628e-01, 1.4329e-01],\n",
            "        [3.3182e-01, 3.6970e-01, 5.7460e-01]])\n",
            "x[:, 0] tensor([0.3258, 0.9467, 0.4718, 0.1102, 0.3318])\n",
            "x[1, :] tensor([0.9467, 0.2810, 0.8448])\n",
            "x[1, 1] tensor(0.2810)\n",
            "x[1,1].item() 0.28100305795669556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "metadata": {
        "id": "f2D2dznXCouO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea11a5e-b1e3-4b25-ed1f-bd827e4291f0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NumPy\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is very easy"
      ],
      "metadata": {
        "id": "rRbfGqafEu77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "id": "JB1OCRrUEyBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf873c03-b67a-4fbf-ca2e-ec7c90d7aa33"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Careful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "kUzV6XdhdwYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf4191f-8002-403a-8140-24d1dbd7e6cc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "c = torch.tensor(a)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "id": "SjHqp4sCeFip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6794a311-89ab-4083-bea9-9fc31d67b28e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPU Support\n",
        "\n",
        "By default all tensors are created on the CPU. But we can also move them to the GPU (if it's available ), or create them directly on the GPU."
      ],
      "metadata": {
        "id": "d0JweYJEFKSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x = torch.rand(2,2).to(device)  # move tensors to GPU device\n",
        "#x = x.to(\"cpu\")\n",
        "#x = x.to(\"cuda\")  \n",
        "\n",
        "x = torch.rand(2,2, device=device)  # or directy create them on GPU"
      ],
      "metadata": {
        "id": "ZKe9RBTzFMRP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Autograd\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. Generally speaking, *torch.autograd* is an engine for computing the vector-Jacobian product. It computes partial derivates while applying the chain rule.\n",
        "\n",
        "Set `requires_grad = True`:"
      ],
      "metadata": {
        "id": "AUNVPAlvxqlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor. \n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "id": "V2uQnrUpw8DA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621579ae-22fb-4639-e839-b4dfd5efdca7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.9821, -2.0953, -1.2364], requires_grad=True)\n",
            "tensor([ 0.0179, -0.0953,  0.7636], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f8388fb66a0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "id": "4mIlnyc-e5-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcb27e1-b550-44cf-edfc-f1bca2a0d854"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.5650e-04, 2.7225e-02, 1.7492e+00], grad_fn=<MulBackward0>)\n",
            "tensor(0.5925, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# !!! Careful!!! backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!! optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "YcSsY7z_IxOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d480e56-f202-43db-9183-4690f2f58183"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([ 0.0357, -0.1905,  1.5272])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stop a tensor from tracking history:\n",
        "For example during the training loop when we want to update our weights, or after training during evaluation. These operations should not be part of the gradient computation. To prevent this, we can use:\n",
        "\n",
        "- `x.requires_grad_(False)`\n",
        "- `x.detach()`\n",
        "- wrap in `with torch.no_grad():`"
      ],
      "metadata": {
        "id": "sqft_WDKgPfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "b = (a * a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "id": "ixsK058BgPJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ad78f6-5dfc-4ec4-b780-ffcc75b4f424"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7f82c005cdc0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "b = a.detach()\n",
        "print(a.requires_grad)\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "id": "5Ry_MsWhfByT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c50a0a-7198-4df8-dacc-82077e5fd48b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    b = a ** 2\n",
        "    print(b.requires_grad)"
      ],
      "metadata": {
        "id": "D1Y9nLXVfFAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf598833-be45-471c-cd50-3b9d5780d403"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Autograd\n",
        "Linear Regression example:\n",
        "\n",
        "$f(x) = w * x + b$\n",
        "\n",
        "here : `f(x) = 2 * x`"
      ],
      "metadata": {
        "id": "L6gdoDj1QZQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x  + b\n",
        "# here : f = 2 * x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "X_test = 5.0\n",
        "\n",
        "print(f'Prediction before training: f({X_test}) = {forward(X_test).item():.3f}')"
      ],
      "metadata": {
        "id": "YDzeYp72xnhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ff599f-fb5a-43aa-c75a-2ca5fde5c88c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100        #Number of generations\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "    \n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.3f}')\n",
        "\n",
        "print(f'Prediction after training: f({X_test}) = {forward(X_test).item():.3f}')"
      ],
      "metadata": {
        "id": "3H_VoUv9pnfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8978785-fa90-4315-ac83-23e040695f68"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: w = 1.998, loss = 0.000\n",
            "epoch 20: w = 2.000, loss = 0.000\n",
            "epoch 30: w = 2.000, loss = 0.000\n",
            "epoch 40: w = 2.000, loss = 0.000\n",
            "epoch 50: w = 2.000, loss = 0.000\n",
            "epoch 60: w = 2.000, loss = 0.000\n",
            "epoch 70: w = 2.000, loss = 0.000\n",
            "epoch 80: w = 2.000, loss = 0.000\n",
            "epoch 90: w = 2.000, loss = 0.000\n",
            "epoch 100: w = 2.000, loss = 0.000\n",
            "Prediction after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model, Loss & Optimizer\n",
        "\n",
        "A typical PyTorch pipeline looks like this:\n",
        "\n",
        "1. Design model (input, output, forward pass with different layers)\n",
        "2. Construct loss and optimizer\n",
        "3. Training loop:\n",
        "  - Forward = compute prediction and loss\n",
        "  - Backward = compute gradients\n",
        "  - Update weights"
      ],
      "metadata": {
        "id": "Vjq9HmRFQjov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x \n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
        "\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "e9HD5KW3QGFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ca49fa-c7da-4720-9e36-3009397c3bc5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples = 8, n_features = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "\n",
        "# Here we could simply use a built-in model from PyTorch\n",
        "# model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define different layers, only one layer for linear regression\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    # Apply layers with forward\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "loss = nn.MSELoss() #Mean Squared Loss\n",
        "#Stochastic Gradient Descent\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)    #Model internally calls forward pass\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()  #Uses gradient\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        w, b = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l.item())\n",
        "\n",
        "print(f'Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "id": "eID-YTrgqNUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e5cead-728e-47ed-bfc7-67c4e5408a51"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = -3.285\n",
            "epoch  10 : w =  1.8626868724822998  loss =  0.12133738398551941\n",
            "epoch  20 : w =  1.8694909811019897  loss =  0.1117640882730484\n",
            "epoch  30 : w =  1.8746094703674316  loss =  0.10317067056894302\n",
            "epoch  40 : w =  1.8795266151428223  loss =  0.0952378436923027\n",
            "epoch  50 : w =  1.8842508792877197  loss =  0.08791503310203552\n",
            "epoch  60 : w =  1.8887897729873657  loss =  0.08115531504154205\n",
            "epoch  70 : w =  1.8931506872177124  loss =  0.0749153196811676\n",
            "epoch  80 : w =  1.8973406553268433  loss =  0.06915511190891266\n",
            "epoch  90 : w =  1.9013662338256836  loss =  0.06383774429559708\n",
            "epoch  100 : w =  1.9052340984344482  loss =  0.05892932042479515\n",
            "Prediction after training: f(5.0) = 10.059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. First Neural Net\n",
        "GPU, Datasets, DataLoader, Transforms, Neural Net, Training & Evaluation\n",
        "\n",
        "Use the same pipeline from 3."
      ],
      "metadata": {
        "id": "M4njny3PUJsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500 \n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = examples.next()\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "dLpCL5NUQzOZ",
        "outputId": "cde9cfa5-f3fa-44ce-88e4-637eb79c1592"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 144425300.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24198101.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 38081005.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 8068838.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-49894ba40db1>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mexample_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass and loss calculation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "udJ5RnoDrOzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model: we don't need to compute gradients\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (output_value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
      ],
      "metadata": {
        "id": "i9x54JYIrTUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. CNN\n",
        "\n",
        "This section covers:\n",
        "\n",
        "- Convolutional Layers\n",
        "- MaxPooling\n",
        "- Save/Load model"
      ],
      "metadata": {
        "id": "yKgzU8XCurGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(imgs):\n",
        "    imgs = imgs / 2 + 0.5   # unnormalize\n",
        "    npimgs = imgs.numpy()\n",
        "    plt.imshow(np.transpose(npimgs, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# one batch of random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "img_grid = torchvision.utils.make_grid(images[0:25], nrow=5)\n",
        "imshow(img_grid)"
      ],
      "metadata": {
        "id": "Sr91YjuQT-XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(64*4*4, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # N, 3, 32, 32\n",
        "        x = F.relu(self.conv1(x))   # -> N, 32, 30, 30\n",
        "        x = self.pool(x)            # -> N, 32, 15, 15\n",
        "        x = F.relu(self.conv2(x))   # -> N, 64, 13, 13\n",
        "        x = self.pool(x)            # -> N, 64, 6, 6\n",
        "        x = F.relu(self.conv3(x))   # -> N, 64, 4, 4\n",
        "        x = torch.flatten(x, 1)     # -> N, 1024\n",
        "        x = F.relu(self.fc1(x))     # -> N, 64\n",
        "        x = self.fc2(x)             # -> N, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "n4ekV872wPF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = ConvNet()\n",
        "loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_correct2 = 0\n",
        "    n_samples = len(test_loader.dataset)\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        outputs2 = loaded_model(images)\n",
        "        _, predicted2 = torch.max(outputs2, 1)\n",
        "        n_correct2 += (predicted2 == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the model: {acc} %')\n",
        "\n",
        "    acc = 100.0 * n_correct2 / n_samples\n",
        "    print(f'Accuracy of the loaded model: {acc} %')"
      ],
      "metadata": {
        "id": "oVIQkMQXsRIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wk4gdclP9yPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}